# 讀取資料庫與資料集、檢查資料屬性與漏值
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score, adjusted_rand_score
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.cluster import AgglomerativeClustering
from sklearn.model_selection import train_test_split

# 讀取資料
file_path = 'HW3_Credit Card Dataset.csv'
df = pd.read_csv(file_path)

# 檢查資料類型與遺漏值
print(df.info())
print(df.isnull().sum())

# 排除 CUST_ID 特徵
df = df.drop(columns=['CUST_ID'])

# 填補遺漏值
df = df.fillna(df.median())

# 確認補值後的資料狀況
print(df.isnull().sum())

# 繪製直方圖
df.hist(bins=30, figsize=(20, 15))
plt.savefig('histograms.png')
plt.show()

# 繪製熱度圖

plt.figure(figsize=(20, 15))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.savefig('heatmap.png')
plt.show()

# PCA降維處理
# 標準化
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)

# PCA 降維
pca = PCA(n_components=2)
df_pca = pca.fit_transform(df_scaled)

# 繪製 PCA 結果
plt.figure(figsize=(10, 7))
plt.scatter(df_pca[:, 0], df_pca[:, 1])
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('PCA Result')
plt.savefig('pca.png')
plt.show()

# 分割資料集
X_train, X_test = train_test_split(df_scaled, test_size=0.2, random_state=42)

# K-means 分群
sse = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_train)
    sse.append(kmeans.inertia_)

# 繪製轉折圖
plt.figure(figsize=(10, 7))
plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('SSE')
plt.title('Elbow Method')
plt.savefig('elbow_method_Start.png')
plt.show()

# 決定集群數量為 3
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_train)
labels = kmeans.labels_

# 將測試集也進行PCA降維
X_test_pca = pca.transform(X_test)

# 繪製散佈圖
plt.figure(figsize=(10, 7))
plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=kmeans.predict(X_test))
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('K-means Clustering')
plt.savefig('kmeans_twist.png')
plt.show()

# 計算輪廓係數與調整蘭德指數
silhouette_kmeans = silhouette_score(X_test, kmeans.predict(X_test))
print(f'Silhouette Score for K-means: {silhouette_kmeans}')

# 階層式分群
linked = linkage(X_train, 'ward')
plt.figure(figsize=(10, 7))
dendrogram(linked)
plt.title('Hierarchical Clustering Dendrogram')
plt.savefig('dendrogram.png')
plt.show()

# 決定集群數量為 3
hc = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')
labels = hc.fit_predict(X_train)

# 將測試集也進行PCA降維
X_test_pca = pca.transform(X_test)

# 繪製散佈圖
plt.figure(figsize=(10, 7))
plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=hc.fit_predict(X_test))
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('Hierarchical Clustering')
plt.savefig('hierarchical_clustering.png')
plt.show()

# 計算輪廓係數與調整蘭德指數
silhouette_hc = silhouette_score(X_test, hc.fit_predict(X_test))
print(f'Silhouette Score for Hierarchical Clustering: {silhouette_hc}')

# DBSCAN 分群
dbscan = DBSCAN(eps=0.5, min_samples=5)
labels = dbscan.fit_predict(X_train)

# 將測試集也進行PCA降維
X_test_pca = pca.transform(X_test)

# 繪製散佈圖
plt.figure(figsize=(10, 7))
plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=dbscan.fit_predict(X_test))
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('DBSCAN Clustering')
plt.savefig('dbscan.png')
plt.show()

# 計算輪廓係數與調整蘭德指數
silhouette_dbscan = silhouette_score(X_test, dbscan.fit_predict(X_test))
print(f'Silhouette Score for DBSCAN: {silhouette_dbscan}')

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)

from sklearn.decomposition import PCA

pca = PCA(n_components=10)  # 使用前10個主成分
df_pca = pca.fit_transform(df_scaled)

# 繪製前兩個主成分的結果
plt.figure(figsize=(10, 7))
plt.scatter(df_pca[:, 0], df_pca[:, 1])
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.title('PCA Result')
plt.savefig('pca_10_components.png')
plt.show()

from sklearn.manifold import TSNE

# 使用 t-SNE 進行降維
tsne = TSNE(n_components=2, random_state=42)
df_tsne = tsne.fit_transform(df_scaled)

# 繪製 t-SNE 結果
plt.figure(figsize=(10, 7))
plt.scatter(df_tsne[:, 0], df_tsne[:, 1])
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.title('t-SNE Result')
plt.savefig('tsne.png')
plt.show()

# 使用 K-means 進行分群
kmeans = KMeans(n_clusters=3, random_state=42)
labels_kmeans = kmeans.fit_predict(df_tsne)

plt.figure(figsize=(10, 7))
plt.scatter(df_tsne[:, 0], df_tsne[:, 1], c=labels_kmeans)
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.title('K-means Clustering on t-SNE Result')
plt.savefig('kmeans_tsne.png')
plt.show()

# 計算 K-means 的輪廓係數
silhouette_kmeans_tsne = silhouette_score(df_tsne, labels_kmeans)
print(f'Silhouette Score for K-means on t-SNE result: {silhouette_kmeans_tsne}')


from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# 使用 Hierarchical Clustering (Agglomerative) 進行分群
hc = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')
labels_hc = hc.fit_predict(df_tsne)

# 繪製 Hierarchical Clustering 的分群結果
plt.figure(figsize=(10, 7))
plt.scatter(df_tsne[:, 0], df_tsne[:, 1], c=labels_hc)
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.title('Hierarchical Clustering on t-SNE Result')
plt.savefig('hierarchical_clustering_tsne.png')
plt.show()

# 計算 Hierarchical Clustering 的輪廓係數
silhouette_hc_tsne = silhouette_score(df_tsne, labels_hc)
print(f'Silhouette Score for Hierarchical Clustering on t-SNE result: {silhouette_hc_tsne}')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# 將信用額度分類
bins_credit = [0, 2000, 5000, np.inf]
labels_credit = ['Low', 'Medium', 'High']
df['Credit_Limit_Category'] = pd.cut(df['CREDIT_LIMIT'], bins=bins_credit, labels=labels_credit)

# 將消費頻率分類
bins_freq = [0, 0.5, 1]
labels_freq = ['Low_Freq', 'High_Freq']
df['Balance_Frequency_Category'] = pd.cut(df['BALANCE_FREQUENCY'], bins=bins_freq, labels=labels_freq)
df['Purchases_Frequency_Category'] = pd.cut(df['PURCHASES_FREQUENCY'], bins=bins_freq, labels=labels_freq)

# 將分類轉換為數值型
df = pd.get_dummies(df, columns=['Credit_Limit_Category', 'Balance_Frequency_Category', 'Purchases_Frequency_Category'], drop_first=True)

# 標準化數據
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)

# t-SNE 降維
tsne = TSNE(n_components=2, random_state=42)
df_tsne = tsne.fit_transform(df_scaled)

# 使用肘部法則找最佳集群數量
sse = []
silhouette_scores = []
k_values = range(2, 11)

for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df_tsne)
    sse.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(df_tsne, kmeans.labels_))

# 繪製肘部法則圖
plt.figure(figsize=(10, 7))
plt.plot(k_values, sse, marker='o')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.title('Elbow Method for Optimal k')
plt.savefig('elbow_method.png')
plt.show()

# 繪製輪廓係數圖
plt.figure(figsize=(10, 7))
plt.plot(k_values, silhouette_scores, marker='o')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score for Optimal k')
plt.savefig('silhouette_score.png')
plt.show()

# 選擇最佳的集群數量
optimal_k = k_values[np.argmax(silhouette_scores)]
print(f'Optimal number of clusters: {optimal_k}')

# 使用最佳集群數量進行 K-means 分群
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
labels_kmeans = kmeans.fit_predict(df_tsne)

# 繪製 t-SNE 的分群結果
plt.figure(figsize=(10, 7))
plt.scatter(df_tsne[:, 0], df_tsne[:, 1], c=labels_kmeans)
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.title(f'K-means Clustering on t-SNE Result (k={optimal_k})')
plt.savefig('kmeans_tsne_optimal_k.png')
plt.show()

# 將分群標籤加入原始資料中
df['Cluster'] = labels_kmeans

# 分析每個集群的消費金額
cluster_summary = df.groupby('Cluster').agg({
    'PURCHASES': ['mean', 'median', 'sum', 'count'],
    'BALANCE': ['mean', 'median', 'sum'],
    'PAYMENTS': ['mean', 'median', 'sum'],
    'CREDIT_LIMIT': ['mean', 'median']
}).reset_index()

# 設置列名稱
cluster_summary.columns = ['Cluster', 
                           'Purchases_Mean', 'Purchases_Median', 'Purchases_Sum', 'Purchases_Count', 
                           'Balance_Mean', 'Balance_Median', 'Balance_Sum', 
                           'Payments_Mean', 'Payments_Median', 'Payments_Sum', 
                           'Credit_Limit_Mean', 'Credit_Limit_Median']

# 打印每個集群的消費金額相關統計
print(cluster_summary)

# 可視化每個集群的消費金額相關統計
plt.figure(figsize=(15, 10))

# 平均消費金額
plt.subplot(2, 2, 1)
sns.barplot(x='Cluster', y='Purchases_Mean', data=cluster_summary)
plt.title('Average Purchases by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Average Purchases')

# 中位數消費金額
plt.subplot(2, 2, 2)
sns.barplot(x='Cluster', y='Purchases_Median', data=cluster_summary)
plt.title('Median Purchases by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Median Purchases')

# 消費金額總和
plt.subplot(2, 2, 3)
sns.barplot(x='Cluster', y='Purchases_Sum', data=cluster_summary)
plt.title('Total Purchases by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Total Purchases')

# 集群大小
plt.subplot(2, 2, 4)
sns.barplot(x='Cluster', y='Purchases_Count', data=cluster_summary)
plt.title('Number of Customers by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Number of Customers')

plt.tight_layout()
plt.savefig('cluster_purchases_summary.png')
plt.show()

# 計算 K-means 的輪廓係數
silhouette_kmeans_tsne = silhouette_score(df_tsne, labels_kmeans)
print(f'Silhouette Score for K-means on t-SNE result: {silhouette_kmeans_tsne}')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 加入分群標籤到原始數據
df['Cluster'] = labels_kmeans

# 計算每個特徵在不同集群中的均值和中位數
cluster_features = df.groupby('Cluster').agg(['mean', 'median']).reset_index()

# 打印每個特徵在不同集群中的均值和中位數
print(cluster_features)

# 可視化每個特徵在不同集群中的分佈
features_to_plot = ['BALANCE', 'BALANCE_FREQUENCY', 'PURCHASES', 'ONEOFF_PURCHASES',
                    'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'PURCHASES_FREQUENCY',
                    'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY',
                    'CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', 'PURCHASES_TRX',
                    'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS', 'PRC_FULL_PAYMENT', 'TENURE']

plt.figure(figsize=(20, 20))
for i, feature in enumerate(features_to_plot, 1):
    plt.subplot(6, 3, i)
    sns.boxplot(x='Cluster', y=feature, data=df)
    plt.title(f'{feature} by Cluster')

plt.tight_layout()
plt.savefig('features_by_cluster.png')
plt.show()


